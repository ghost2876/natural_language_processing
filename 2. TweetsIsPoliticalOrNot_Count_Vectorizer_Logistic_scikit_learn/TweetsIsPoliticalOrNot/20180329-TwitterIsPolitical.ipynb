{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_and_labels(filename):\n",
    "    import pandas as pd\n",
    "    \n",
    "    df = pd.read_csv(filename, header=None, sep='\\t')\n",
    "    x = df.iloc[:,1]\n",
    "    y = df.iloc[:,0]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y = get_data_and_labels('general-tweets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Bumping dj sefs mixtape nowww this is my music...\n",
       "1    #ieroween THE STORY OF IEROWEEN! THE VIDEO ->>...\n",
       "2    trick or treating at the mall today; ZOO! last...\n",
       "3    @Ussk81 PMSL!!! I try not to stare but I can't...\n",
       "4    @Sc0rpi0n676 btw - is there a remote chance i ...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NOT\n",
       "1    NOT\n",
       "2    NOT\n",
       "3    NOT\n",
       "4    NOT\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Global Voices Online Â» Alex Castro: A liberal...\n",
       "1    Do the Conservatives Have a Death Wish? http:/...\n",
       "2    @MMFlint I've seen all of your movies and Capi...\n",
       "3    RT @AllianceAlert: * House Dems ask for civili...\n",
       "4    RT @AdamSmithInst Quote of the week: My politi...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x, test_y = get_data_and_labels('keyword-tweets.txt')\n",
    "test_x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    POLIT\n",
       "1    POLIT\n",
       "2      NOT\n",
       "3    POLIT\n",
       "4    POLIT\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2004"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_labels(labels):\n",
    "    from sklearn import preprocessing\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    return le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y     test_y\n",
    "0 = NOT    POLIT = 0\n",
    "    NOT    NOT = 1\n",
    "1 = POLIT  NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一label, 即0 1编码\n",
    "le = encode_labels(train_y)\n",
    "train_targets = le.transform(train_y)\n",
    "test_targets = le.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "以下，弄什么Bag of words\n",
    "Giving up my favorite vice ...    Republican\n",
    "1      1  1  1        1           0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建出features set，之前的train_targets就是labels set\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "x_train_counts = count_vect.fit_transform(train_x).toarray()\n",
    "x_test_counts = count_vect.transform(test_x).toarray()\n",
    "x_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.15618762475\n",
      "Confusion Matrix: [[ 313    0]\n",
      " [1691    0]]\n"
     ]
    }
   ],
   "source": [
    "# 从confusion matrix我们可以解读到，nothing is predicted as 1, everything is predicted as 0\n",
    "# This is called inbalance problem, we have got tons of inpolitical tweets but only little political tweets\n",
    "# clf means classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(x_train_counts, train_targets)\n",
    "hyp = clf.predict(x_test_counts)\n",
    "\n",
    "print ('Accuracy:', accuracy_score(test_targets, hyp))\n",
    "print ('Confusion Matrix:', confusion_matrix(test_targets, hyp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9048)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如何解决上述问题，how many features do we have? 因为input是matrix，所以shape后发现我们有9048个features（9048个words），2000是sample data record count\n",
    "# 所以我们发现for training data, the predictor count (9048) is far more larger than the training data count (2000), so you lose the degree of freedom\n",
    "x_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LASSO regression, also called L1 norm regression\n",
    "\n",
    "\n",
    "the larger the C, the tighter the constraint.\n",
    "\n",
    "\n",
    "          (optimal performance)\n",
    " |x2\n",
    "/|\\\n",
    "-------->x1\n",
    "\\|/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.0001 ... accuracy: 0.15618762475\n",
      "C =  0.0001 ... accuracy: 0.15618762475\n",
      "C =  0.01 ... accuracy: 0.15618762475\n",
      "C =  0.1 ... accuracy: 0.15618762475\n",
      "C =  1 ... accuracy: 0.199600798403\n",
      "C =  10 ... accuracy: 0.26996007984\n",
      "C =  100 ... accuracy: 0.287425149701\n",
      "C =  1000 ... accuracy: 0.289421157685\n",
      "C =  10000 ... accuracy: 0.214570858283\n"
     ]
    }
   ],
   "source": [
    "# accuracy有望从之前15%提升到接近30%\n",
    "C = [0.0001, 0.0001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l1', C=c)\n",
    "    clf.fit(x_train_counts, train_targets)\n",
    "    hyp = clf.predict(x_test_counts)\n",
    "    accuracy = accuracy_score(test_targets, hyp)\n",
    "    print ('C = ', c, '... accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  [[ 276   37]\n",
      " [1389  302]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix for best system of the above\n",
    "# better than before but still not good\n",
    "clf = LogisticRegression(penalty='l1', C=100)\n",
    "clf.fit(x_train_counts, train_targets)\n",
    "hyp = clf.predict(x_test_counts)\n",
    "\n",
    "print ('Confusion Matrix: ', confusion_matrix(test_targets, hyp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
